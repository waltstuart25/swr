{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy                1.24.3              \n",
      "pandas               2.0.2               \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "print(f\"numpy                {np.__version__:<20}\")\n",
    "print(f\"pandas               {pd.__version__:<20}\")\n",
    "\n",
    "import pytest\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CRRA utility: \n",
    "\n",
    "- Suppose you are offered a coin flip for \\$2, how much would you pay?\n",
    "- Probably no more than \\$1\n",
    "- Probably a bit less than \\$1, reflecting a risk premium. You demand a higher return for taking the risk.\n",
    "- Suppose you are offered a retirement annuity of \\$10,000 per year, how much would you pay? Probably about the NPV using some discount rate\n",
    "- Suppose you are offered a variable annuity that draws the payment from some distribution. How much would you pay? Probably a little less: The NPV using a slightly higher discount rate reflecting a risk premium.\n",
    "- A related question is how much of your net worth you would invest in a positive EV bet. If your preference is to always invest the same share of your net worth, you exhibit constant relative risk aversion, or CRRA. It just means you don't become more or less risk averse as you become more wealthy. The risk premium you demand for a given bet that is a given fraction of your wealth always remains the same.\n",
    "- If you tell me you the amount of the risk premium you demand, and that you always invest the same fraction of your net worth, I can tell you that your utility function looks like the below and also what your $\\gamma$ risk aversion parameter is:\n",
    "\n",
    "1) $u(c) = \\frac{c^{1-\\gamma} -1}{1-\\gamma}$\n",
    "\n",
    "- Using this formula, I can derive your risk premium or equivalently the amount you would pay for the variable annuity. If your utility is given by the formula above, I can calculate the equivalent constant payment stream as the inverse function\n",
    "\n",
    "2) $c = {(1 + u(c) (1 - \\gamma))}^\\frac{1}{1 -\\gamma}$\n",
    "\n",
    "To value a variable income stream, I convert it to utility using formula 1 and my risk aversion parameter, then convert the utility to the equivalent constant stream of cash using formula 2). Then I can discount that stream at the risk free rate and that tells me what the variable risk stream is worth.\n",
    "\n",
    "https://en.wikipedia.org/wiki/Isoelastic_utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so here's how I think about this utility function. \n",
    "# utility is a slightly fraught topic.\n",
    "# in school I was taught that you shouldn't think about cardinal utility, only ordinal utility. \n",
    "# i.e. people can rank preferences but you can't sum utilities, especially across people.\n",
    "# but if an individual can rank their preferences using indifference curves, there is always \n",
    "# some cardinal utility function that will give the same result. you can just count how many indifference curves\n",
    "# separate any alternatives from a base case, i.e. integrate across the isocurves.\n",
    "# here are some reasons you might not want to think that way\n",
    "# base case is arbitrary\n",
    "# you can't sum utilities, i.e. complementarity comes into play\n",
    "# the form of the utility function is controversial, once you choose a utility function, you've largely determined\n",
    "# the nature of the economic 'game' and proper policy. (As a for-instance, if you believe all people should count equally\n",
    "# in the social welfare function and individuals have decreasing marginal utility of wealth or income, you will tend\n",
    "# to think equality is a social good. This offends some people. It's not enough to say more equality is better, but \n",
    "# there are tradeoffs with efficiency, liberty, allowing a free people a full measure of self-realization. Economic\n",
    "# 'neutrality' means saying you're entitled to believe social welfare is fully subjective and you shouldn't worry\n",
    "# about equality and it's a legitimate subjective choice to ignore some people's welfare entirely).\n",
    "# \n",
    "# you might think this utility function is unrealistic and complicated and abstract. and that's OK. just plug in \n",
    "# your own version. at the end of the day you have to optimize something. to me the CRRA utility is the absolute\n",
    "# rock bottom simplest thing you can maximize, and it will take into acount risk tolerance in a reasonable way.\n",
    "\n",
    "# my gut is that a human being's relative risk tolerance decreases as they grow more wealthy, as implied by Maslow's \n",
    "# hierarchy of needs. It starts high. if your wealth and income and status falls below some minimum temporarily,\n",
    "# it is very unpleasant and you can have permanent social, health repercussions. increased stress, lose social status, \n",
    "# you are at risk of homelessness, loss of shelter, health care, food. And even if you have more than you need\n",
    "# each consecutve doubling probably yields some more or less constant positive desirability, even for the richest\n",
    "# mogul or king, suggesting log utility. If you're Elon Musk and you have $100b, and you bet according to Kelly,\n",
    "# you maximize your growth rate and you have a 50% chance of at some point losing 50% of your wealth, 1% chance of\n",
    "# of losing 99% of your wealth, which would leave you with $1b and still in the very long run almost certainly better\n",
    "# off.\n",
    "\n",
    "# the bottom line is, you have to maximize something, and this is the simplest thing I can think of that makes sense.\n",
    "# be literally dead. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# monte carlo like this is generally a pretty bad way to model financial time series\n",
    "# not all the things that can happen did happen\n",
    "# what did happen didn't happen according to its long-term distribution (sampling error). \n",
    "# you could estimate the long term distribution and sample from it.  i.e. generate random log normal data per the correlation matrix. but there is no generally accepted form of the distribution. log normal only a poor approximation. \n",
    "# the distribution changes, the real economy and financial structure are totally different from 90 years ago with gold standard, manufacturing/agrarian, less globally integrated supply chains and financial system, different taxes, financial system, politics and wars\n",
    "# financial time series are serially correlated. if you have a crash in October, due annual averaging, \n",
    "# it will impact the current and the following year. financial time series discretize decisions that \n",
    "# sometimes play out over multiple time periods, sometimes occur multiple times in a single time period. \n",
    "# sometimes you have data anomalies that reverse the following period.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turtles all the way down\n",
    "\n",
    "# maybe growth will continue, we'll harness clean energy, eventually build a Dyson sphere\n",
    "# maybe we'll hit limits to growth and blow up\n",
    "# maybe we'll just continue to have punctuated equilibria and evolution\n",
    "\n",
    "# you want to do something that never failed in history, and also has acceptable failure under monte carlo. they will always be that monte carlo trial that has 5 1929s in a row and it's not surivivable.\n",
    "\n",
    "# be conservative because things are worse, than expected, even taking into account murphy's law.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.01      , 0.0198    , 0.029106  , 0.03764376, 0.04517251,\n",
       "       0.05149666, 0.05647467, 0.06002451, 0.06212537, 0.06281565,\n",
       "       0.06218749, 0.0603784 , 0.05756074, 0.05392999, 0.04969263,\n",
       "       0.04505465, 0.04021128, 0.03533862, 0.03058754, 0.0260799 ,\n",
       "       0.02190712, 0.01813075, 0.0147848 , 0.01187927, 0.00940442,\n",
       "       0.00733545, 0.00563701, 0.00426742, 0.00318228, 0.0077911 ])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute CE cash flow with a mortality curve\n",
    "\n",
    "# compute % of original cohort that dies each year\n",
    "# mortality starts at 1% in year one and goes up linearly by 1% each year\n",
    "mortality = np.linspace(0.00, 1.0, 101)\n",
    "survivorship = np.cumprod(1-mortality[:31])\n",
    "deathrate = -np.diff(survivorship)\n",
    "# top up last 1 to get to \n",
    "deathrate[-1] += 1- np.sum(deathrate)\n",
    "print (\"sum\", np.sum(deathrate))\n",
    "deathrate\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([38.07947177, 95.12071633, 73.46740024, 60.26718994, 16.4458454 ,\n",
       "       16.44345751,  6.7502776 , 86.75143843, 60.51038616, 71.0991852 ,\n",
       "        3.03786494, 97.02107536, 83.41182144, 22.02157196, 19.00067175,\n",
       "       19.15704648, 31.11998205, 52.95088673, 43.76255685, 29.83168488,\n",
       "       61.57343658, 14.8098922 , 29.9223202 , 37.26982249, 46.15092844,\n",
       "       78.73242018, 20.76770443, 51.9092094 , 59.64904232,  5.59859086])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random cashflows\n",
    "cashflows = np.random.uniform(1, 100, 30)\n",
    "cashflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.63967534, 4.55514678, 4.29684177, 4.09878784, 2.80007289,\n",
       "       2.79992768, 1.90958363, 4.463047  , 4.10281502, 4.26407588,\n",
       "       1.11115494, 4.57492823, 4.42379004, 3.09202252, 2.94447433,\n",
       "       2.95267061, 3.43785012, 3.96936482, 3.77877859, 3.39557108,\n",
       "       4.12023055, 2.69529535, 3.3986047 , 3.61818395, 3.83191708,\n",
       "       4.36605502, 3.03339911, 3.94949622, 4.08847809, 1.72251493])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# utility, for example log utility (gamma = 1)\n",
    "u = np.log(cashflows)\n",
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = np.indices(u.shape)[0]+1\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.63967534, 4.09741106, 4.16388797, 4.14761293, 3.87810492,\n",
       "       3.69840872, 3.44286228, 3.57038537, 3.62954422, 3.69299738,\n",
       "       3.45828443, 3.55133808, 3.61844977, 3.58084783, 3.53842293,\n",
       "       3.50181341, 3.49805086, 3.52423497, 3.537632  , 3.53052896,\n",
       "       3.55860998, 3.51936841, 3.51411781, 3.5184539 , 3.53099243,\n",
       "       3.56311022, 3.54349129, 3.55799147, 3.57628411, 3.5144918 ])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cumulative mean utility\n",
    "mean_u = np.cumsum(u)/indices\n",
    "mean_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  38.07947177,  120.3685446 ,  192.96334598,  253.13103899,\n",
       "        241.66267216,  242.2979546 ,  218.93446207,  284.24226157,\n",
       "        339.26068512,  401.65056775,  349.38683112,  418.31918156,\n",
       "        484.63650235,  502.65555566,  516.18907746,  530.80893156,\n",
       "        561.86645922,  610.70054169,  653.32256476,  682.84044909,\n",
       "        737.40142762,  742.78814031,  772.48456618,  809.57363536,\n",
       "        853.94625157,  917.09105093,  933.86151596,  982.59396472,\n",
       "       1036.47409588, 1007.96546332])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert utility back to cash flow and multiply by number of years for cumulative ce cash flow\n",
    "ce = np.exp(mean_u) * indices\n",
    "ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "436.58452788516126"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# experienced cumulative CE cash flow \n",
    "# multiply each year's % who died in that year by cumulative CE cash flow up to that year\n",
    "# and then sum for average experienced total cash flow\n",
    "madj_ce = np.sum(ce * deathrate)\n",
    "madj_ce\n",
    "\n",
    "# (there's a (weak) argument for using the average, \n",
    "# i.e. adjusting to equal weight the guy who died in year 1 with the guy who died in year 30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# that is the CE value of 1 cohort's experienced outcome\n",
    "# if I have a strategy and I want the CE value of the whole history of all cohorts\n",
    "# take the CE value experience of each cohort\n",
    "# model the value of the whole history as if you were drawing the experience of one cohort at random \n",
    "# so take the CE value of all the CE values (i.e. discount the risk not only within each cohort but over all cohorts)\n",
    "# and that's the value of your comprehensive retirement strategy, adjusted for risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crra_ce(cashflows, gamma):\n",
    "    \"\"\"takes a numpy array, returns total CRRA certainty-equivalent cash flow\"\"\"\n",
    "    # calibration factor to make the total CE cash flow for Bengen rule == 0.1, to reduce numerical problems\n",
    "    # for gamma > 1, there is an upper bound to utility 1/(gamma-1)\n",
    "    # when utility approaches this limit, small improvements in cash flow don't numerically change utility\n",
    "    # when you multiply cash flow by a factor, CE cash flow is multiplied by same factor, optimality is invariant\n",
    "    # but we convert units back before returning so units in/out are invariant\n",
    "    calibration_factor = len(cashflows) * 4 * 10\n",
    "    cashflows = cashflows/calibration_factor\n",
    "    \n",
    "    # for retirement study assume no negative cashflows\n",
    "    if np.any(np.where(cashflows < 0, 1, 0)):\n",
    "        return 0.0\n",
    "    elif gamma >= 1.0 and 0 in cashflows:\n",
    "        return 0.0\n",
    "    elif gamma == 1.0:\n",
    "        # general formula for CRRA utility undefined for gamma = 1 but limit as gamma->1 = log\n",
    "        u = np.mean(np.log(cashflows))\n",
    "        ce = np.exp(u)\n",
    "    elif gamma == 2.0:  # simple optimization\n",
    "        u2 = np.mean(1 - 1.0 / cashflows)\n",
    "        ce = 1.0 / (1.0 - u2)\n",
    "    elif gamma > 4.0:\n",
    "        # force computations as longdouble for more precision, but always return np.float\n",
    "        gamma = np.longdouble(gamma)\n",
    "        cashflows = cashflows.astype(np.longdouble)\n",
    "        gamma_m1 = gamma - 1.0\n",
    "        gamma_m1_inverse = 1.0 / gamma_m1\n",
    "        u = np.mean(gamma_m1_inverse - 1.0 / (gamma_m1 * cashflows ** gamma_m1))\n",
    "        ce = 1.0 / (1.0 - gamma_m1 * u) ** gamma_m1_inverse\n",
    "        ce = np.float(ce)\n",
    "    elif gamma > 1.0:\n",
    "        gamma_m1 = gamma - 1.0\n",
    "        gamma_m1_inverse = 1.0 / gamma_m1\n",
    "        u = np.mean(gamma_m1_inverse - 1.0 / (gamma_m1 * cashflows ** gamma_m1))\n",
    "        ce = 1.0 / (1.0 - gamma_m1 * u) ** gamma_m1_inverse\n",
    "    else:  # general formula\n",
    "        g_1m = 1 - gamma\n",
    "        u = np.mean((cashflows ** g_1m - 1.0) / g_1m)\n",
    "        ce = (g_1m * u + 1.0) ** (1.0 / g_1m)\n",
    "\n",
    "    return ce * len(cashflows) * calibration_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crra_ce_deathrate(cashflows, gamma, deathrate):\n",
    "    \"\"\"ce cash flow with a mortality curve\n",
    "    cash flows = real cash flows in each year of cohort\n",
    "    gamma = risk aversion\n",
    "    death rate = % of cohort that died in each year of cohort\n",
    "    \n",
    "    compute utility of each cash flow under gamma\n",
    "    compute cumulative mean of utilities up to each year\n",
    "    convert utilities back to CE cash flows\n",
    "    each member of cohort that died in a given year experienced CE cash flow * years alive\n",
    "    \"\"\"\n",
    "    # for retirement study assume no negative cashflows\n",
    "    if np.any(np.where(cashflows < 0, 1, 0)):\n",
    "        return 0.0\n",
    "    else:\n",
    "        calibration_factor = len(cashflows) * 4 * 10\n",
    "        cashflows = cashflows/calibration_factor\n",
    "        \n",
    "        # 1..lastyear\n",
    "        indices = np.indices(cashflows.shape)[0]+1\n",
    "        \n",
    "        if gamma == 1.0:\n",
    "            # utility\n",
    "            u = np.log(cashflows)\n",
    "            # cumulative mean utility\n",
    "            u_mean = np.cumsum(u)/indices\n",
    "            # cumulative mean ce cash flows\n",
    "            ce = np.exp(u_mean) * indices\n",
    "        elif gamma == 2.0:  # simple optimization\n",
    "            u2 = 1 - 1.0 / cashflows\n",
    "            u2_mean = np.cumsum(u2)/indices\n",
    "            ce = 1.0 / (1.0 - u2_mean) * indices\n",
    "        elif gamma > 4.0:\n",
    "            # force computations as longdouble for more precision, but always return np.float\n",
    "            gamma = np.longdouble(gamma)\n",
    "            cashflows = cashflows.astype(np.longdouble)\n",
    "            gamma_m1 = gamma - 1.0\n",
    "            gamma_m1_inverse = 1.0 / gamma_m1\n",
    "            u = gamma_m1_inverse - 1.0 / (gamma_m1 * cashflows ** gamma_m1)\n",
    "            u_mean = np.cumsum(u)/indices\n",
    "            ce = 1.0 / (1.0 - gamma_m1 * u_mean) ** gamma_m1_inverse\n",
    "            ce = (ce * indices).astype(float)\n",
    "        elif gamma > 1.0:\n",
    "            gamma_m1 = gamma - 1.0\n",
    "            gamma_m1_inverse = 1.0 / gamma_m1\n",
    "            u = gamma_m1_inverse - 1.0 / (gamma_m1 * cashflows ** gamma_m1)\n",
    "            u_mean = np.cumsum(u)/indices\n",
    "            ce = 1.0 / (1.0 - gamma_m1 * u_mean) ** gamma_m1_inverse\n",
    "            ce = ce * indices\n",
    "        else:  # general formula\n",
    "            gamma_1m = 1 - gamma\n",
    "            u = (cashflows ** gamma_1m - 1.0) / gamma_1m\n",
    "            u_mean = np.cumsum(u)/indices\n",
    "            ce = (gamma_1m * u_mean + 1.0) ** (1.0 / gamma_1m)\n",
    "            ce = ce * indices\n",
    "        # mortality_adjusted ce cash flows\n",
    "        madj_ce = np.sum(ce * deathrate)\n",
    "        return madj_ce * calibration_factor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test 0 and -1\n",
    "testseries = np.random.uniform(1, 100, 100)\n",
    "testseries[50] = 0.0\n",
    "assert crra_ce(testseries, 1) == 0, \"bad value\"\n",
    "testseries[50] = -1.0\n",
    "assert crra_ce(testseries, 1) == 0, \"bad value\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 99.99999999985576\n",
      "0.5 99.9999999999992\n",
      "1 99.99999999999983\n",
      "2 100.0\n",
      "4 100.00000000000004\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'float'.\n`np.float` was a deprecated alias for the builtin `float`. To avoid this error in existing code, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m testseries \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mones(\u001b[39m100\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m gamma \u001b[39min\u001b[39;00m [\u001b[39m0\u001b[39m, \u001b[39m0.5\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m4\u001b[39m, \u001b[39m8\u001b[39m, \u001b[39m16\u001b[39m]:\n\u001b[0;32m----> 4\u001b[0m     \u001b[39mprint\u001b[39m(gamma, crra_ce(testseries, gamma))\n\u001b[1;32m      5\u001b[0m     \u001b[39massert\u001b[39;00m crra_ce(testseries, gamma) \u001b[39m==\u001b[39m pytest\u001b[39m.\u001b[39mapprox(np\u001b[39m.\u001b[39msum(testseries), \u001b[39m0.0000001\u001b[39m)\n",
      "Cell \u001b[0;32mIn[13], line 31\u001b[0m, in \u001b[0;36mcrra_ce\u001b[0;34m(cashflows, gamma)\u001b[0m\n\u001b[1;32m     29\u001b[0m     u \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmean(gamma_m1_inverse \u001b[39m-\u001b[39m \u001b[39m1.0\u001b[39m \u001b[39m/\u001b[39m (gamma_m1 \u001b[39m*\u001b[39m cashflows \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m gamma_m1))\n\u001b[1;32m     30\u001b[0m     ce \u001b[39m=\u001b[39m \u001b[39m1.0\u001b[39m \u001b[39m/\u001b[39m (\u001b[39m1.0\u001b[39m \u001b[39m-\u001b[39m gamma_m1 \u001b[39m*\u001b[39m u) \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m gamma_m1_inverse\n\u001b[0;32m---> 31\u001b[0m     ce \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mfloat(ce)\n\u001b[1;32m     32\u001b[0m \u001b[39melif\u001b[39;00m gamma \u001b[39m>\u001b[39m \u001b[39m1.0\u001b[39m:\n\u001b[1;32m     33\u001b[0m     gamma_m1 \u001b[39m=\u001b[39m gamma \u001b[39m-\u001b[39m \u001b[39m1.0\u001b[39m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/py310/lib/python3.10/site-packages/numpy/__init__.py:305\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    300\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    301\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIn the future `np.\u001b[39m\u001b[39m{\u001b[39;00mattr\u001b[39m}\u001b[39;00m\u001b[39m` will be defined as the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    302\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mcorresponding NumPy scalar.\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFutureWarning\u001b[39;00m, stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m    304\u001b[0m \u001b[39mif\u001b[39;00m attr \u001b[39min\u001b[39;00m __former_attrs__:\n\u001b[0;32m--> 305\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(__former_attrs__[attr])\n\u001b[1;32m    307\u001b[0m \u001b[39m# Importing Tester requires importing all of UnitTest which is not a\u001b[39;00m\n\u001b[1;32m    308\u001b[0m \u001b[39m# cheap import Since it is mainly used in test suits, we lazy import it\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[39m# here to save on the order of 10 ms of import time for most users\u001b[39;00m\n\u001b[1;32m    310\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m    311\u001b[0m \u001b[39m# The previous way Tester was imported also had a side effect of adding\u001b[39;00m\n\u001b[1;32m    312\u001b[0m \u001b[39m# the full `numpy.testing` namespace\u001b[39;00m\n\u001b[1;32m    313\u001b[0m \u001b[39mif\u001b[39;00m attr \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtesting\u001b[39m\u001b[39m'\u001b[39m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'float'.\n`np.float` was a deprecated alias for the builtin `float`. To avoid this error in existing code, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations"
     ]
    }
   ],
   "source": [
    "# a constant series should always be sum of cash flows for any gamma\n",
    "testseries = np.ones(100)\n",
    "for gamma in [0, 0.5, 1, 2, 4, 8, 16]:\n",
    "    print(gamma, crra_ce(testseries, gamma))\n",
    "    assert crra_ce(testseries, gamma) == pytest.approx(np.sum(testseries), 0.0000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 4913.441232636373 4913.441232636358\n",
      "0.5 4393.680124057666 4393.68012405766\n",
      "1 3734.955584397617 3734.9555843976204\n",
      "2 2056.766184643597 2056.7661846435963\n",
      "4 575.7431234707183 575.743123470718\n",
      "8 282.21136564731336 282.21136564731336\n",
      "15 208.07151484074058 208.07151484074055\n"
     ]
    }
   ],
   "source": [
    "testseries = np.random.uniform(1, 100, 100)\n",
    "\n",
    "def general_ce(cashflows, gamma):\n",
    "    cashflows = np.longdouble(cashflows)\n",
    "    if gamma == 1:\n",
    "        u = np.mean(np.log(cashflows))\n",
    "        ce = np.exp(u)\n",
    "    else:\n",
    "        u = np.mean((cashflows ** (1-gamma) -1) / (1-gamma))\n",
    "        ce = (1 + u * (1-gamma)) ** (1/(1-gamma))\n",
    "    ce = np.float(ce)\n",
    "    return ce * len(cashflows)\n",
    "\n",
    "# can't go to 16 without some numerical problems\n",
    "for gamma in [0, 0.5, 1, 2, 4, 8, 15]:\n",
    "    print(gamma, crra_ce(testseries, gamma), general_ce(testseries, gamma))\n",
    "    assert crra_ce(testseries, gamma) == pytest.approx(general_ce(testseries, gamma), 0.000001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 4913.441232636373 4913.441232636195\n",
      "0.5 4393.680124057666 4393.680124057666\n",
      "1 3734.955584397617 3734.955584397623\n",
      "2 2056.766184643597 2056.7661846435967\n",
      "4 575.7431234707183 575.7431234707183\n",
      "8 282.21136564731336 282.21136564731336\n",
      "16 203.68973076129703 203.68973076129706\n"
     ]
    }
   ],
   "source": [
    "# if everyone dies in last year, mortality-adjusted CE = unadjusted CE\n",
    "deathrate = np.zeros(100)\n",
    "deathrate[99] = 1.0\n",
    "\n",
    "# can't go too high without some numerical problems\n",
    "for gamma in [0, 0.5, 1, 2, 4, 8, 16]:\n",
    "    print(gamma, crra_ce(testseries, gamma), crra_ce_deathrate(testseries, gamma, deathrate))\n",
    "    assert crra_ce(testseries, gamma) == pytest.approx(general_ce(testseries, gamma), 0.000001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06666666666666666667"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamma = 16\n",
    "gamma = np.longdouble(gamma)\n",
    "cashflows = cashflows.astype(np.longdouble)\n",
    "gamma_m1 = gamma - 1.0\n",
    "gamma_m1_inverse = 1.0 / gamma_m1\n",
    "gamma_m1_inverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.06666667, 0.06666667, 0.06666667, 0.06666667, 0.06666667,\n",
       "       0.06666667, 0.06666667, 0.06666667, 0.06666667, 0.06666667,\n",
       "       0.06666666, 0.06666667, 0.06666667, 0.06666667, 0.06666667,\n",
       "       0.06666667, 0.06666667, 0.06666667, 0.06666667, 0.06666667,\n",
       "       0.06666667, 0.06666667, 0.06666667, 0.06666667, 0.06666667,\n",
       "       0.06666667, 0.06666667, 0.06666667, 0.06666667, 0.06666667],\n",
       "      dtype=float128)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = gamma_m1_inverse - 1.0 / (gamma_m1 * cashflows ** gamma_m1)\n",
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.06666667, 0.06666667, 0.06666667, 0.06666667, 0.06666667,\n",
       "       0.06666667, 0.06666667, 0.06666667, 0.06666667, 0.06666667,\n",
       "       0.06666666, 0.06666667, 0.06666667, 0.06666667, 0.06666667,\n",
       "       0.06666667, 0.06666667, 0.06666667, 0.06666667, 0.06666667,\n",
       "       0.06666667, 0.06666667, 0.06666667, 0.06666667, 0.06666667,\n",
       "       0.06666667, 0.06666667, 0.06666667, 0.06666667, 0.06666667],\n",
       "      dtype=float128)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_mean = np.cumsum(u)/indices\n",
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-23-b9e78fc1a9eb>:1: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  ce = 1.0 / (1.0 - gamma_m1 * u_mean) ** gamma_m1_inverse\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([        inf,         inf,         inf,         inf, 19.24840058,\n",
       "       17.88902061,  7.68531085,  7.75403178,  7.8151576 ,  7.87024548,\n",
       "        3.56446585,  3.58520254,  3.60438496,  3.6222366 ,  3.63893554,\n",
       "        3.65462604,  3.66942662,  3.68343587,  3.6967367 ,  3.70939952,\n",
       "        3.72148465,  3.73304413,  3.74412323,  3.75476155,  3.76499392,\n",
       "        3.77485119,  3.78436075,  3.7935471 ,  3.8024322 ,  3.81100937],\n",
       "      dtype=float128)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ce = 1.0 / (1.0 - gamma_m1 * u_mean) ** gamma_m1_inverse\n",
    "ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 OK\n",
      "1 OK\n",
      "2 OK\n",
      "3 OK\n",
      "4 OK\n",
      "5 OK\n",
      "6 OK\n",
      "7 OK\n",
      "8 OK\n",
      "9 OK\n",
      "10 100000.0 0.0\n",
      "11 100000.0 0.0\n",
      "12 100000.0 0.0\n",
      "13 31622.776601683792 0.0\n",
      "14 31622.776601683792 0.0\n",
      "15 31622.776601683792 nan\n",
      "16 31622.776601683792 nan\n",
      "17 31622.776601683792 nan\n",
      "18 31622.776601683792 nan\n",
      "19 31622.776601683792 0.0\n",
      "20 10000.0 0.0\n",
      "21 10000.0 0.0\n",
      "22 10000.0 0.0\n",
      "23 10000.0 0.0\n",
      "24 10000.0 0.0\n",
      "25 10000.0 0.0\n",
      "26 10000.0 0.0\n",
      "27 10000.0 0.0\n",
      "28 10000.0 nan\n",
      "29 10000.0 nan\n",
      "30 10000.0 nan\n",
      "31 10000.0 nan\n",
      "32 10000.0 0.0\n",
      "33 10000.0 nan\n",
      "34 10000.0 0.0\n",
      "35 10000.0 nan\n",
      "36 10000.0 0.0\n",
      "37 10000.0 0.0\n",
      "38 10000.0 0.0\n",
      "39 10000.0 nan\n",
      "40 10000.0 0.0\n",
      "41 10000.0 0.0\n",
      "42 10000.0 0.0\n",
      "43 10000.0 0.0\n",
      "44 3162.2776601683795 0.0\n",
      "45 3162.2776601683795 0.0\n",
      "46 10000.0 0.0\n",
      "47 3162.2776601683795 0.0\n",
      "48 3162.2776601683795 nan\n",
      "49 3162.2776601683795 0.0\n",
      "50 3162.2776601683795 nan\n",
      "51 3162.2776601683795 0.0\n",
      "52 3162.2776601683795 nan\n",
      "53 3162.2776601683795 0.0\n",
      "54 3162.2776601683795 nan\n",
      "55 3162.2776601683795 nan\n",
      "56 3162.2776601683795 nan\n",
      "57 3162.2776601683795 nan\n",
      "58 3162.2776601683795 nan\n",
      "59 3162.2776601683795 nan\n",
      "60 3162.2776601683795 0.0\n",
      "61 3162.2776601683795 nan\n",
      "62 3162.2776601683795 0.0\n",
      "63 3162.2776601683795 0.0\n",
      "64 3162.2776601683795 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-b38b14863696>:30: RuntimeWarning: invalid value encountered in longdouble_scalars\n",
      "  ce = 1.0 / (1.0 - gamma_m1 * u) ** gamma_m1_inverse\n",
      "<ipython-input-13-b38b14863696>:30: RuntimeWarning: divide by zero encountered in longdouble_scalars\n",
      "  ce = 1.0 / (1.0 - gamma_m1 * u) ** gamma_m1_inverse\n"
     ]
    }
   ],
   "source": [
    "# test numerical precision\n",
    "# if we get to 100x Bengen = 12000 we're definitely OK, 20x = 2400 probably OK\n",
    "# fails first around gamma = 20\n",
    "maxgamma = 64\n",
    "failed = False\n",
    "for gamma in range(maxgamma+1):\n",
    "    for calibration in np.logspace(0, 5, 11):\n",
    "        test_series = np.ones(30) * calibration\n",
    "        # can I distinguish a change in 1 unit per year\n",
    "        difference = crra_ce(test_series + 1, gamma) - crra_ce(test_series, gamma)\n",
    "        if np.isfinite(difference) and difference > 0:  # could also check approximately 30\n",
    "            continue\n",
    "        else:\n",
    "            print(gamma, calibration, difference)\n",
    "            failed = True\n",
    "            break\n",
    "    if not failed:\n",
    "        print(gamma, \"OK\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it's worth noting that when gamma > 1\n",
    "# lim(U) as x->infinity is bounded by 1/gamma\n",
    "# in other words as wealth increases, utility increases, by less and less and there is a hard limit utility never exceeds\n",
    "# some people find this highly objectionable on philosophical grounds. for one thing, for sufficiently high gamma there are some bets you will never take because in utility terms they would need a higher utility payoff than hard limit\n",
    "# for some size bet, no bet will be accepted regardless of the odds, because the utility risked is more than the maximum utility available to game\n",
    "# on the other hand, any bet accepted at any level will always be acepted at the same % of wealth for any level of wealth\n",
    "# I'm not particularly sure how I feel about that, other than it creates thorny philosophical and numerical issues and I want to stay away from thorny philosophical and numerical problems. \n",
    "# numerically you want to scale your inputs so that implicitly the hard limit beyond which utility increases are too small to measure is e.g. billions and not hundreds of dollars.\n",
    "# important to be cognizant of that hard limit because once you get in its vicinity increases in utility are very small and you run into numerical problems\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
